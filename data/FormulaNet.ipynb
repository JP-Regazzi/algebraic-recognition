{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Tuple"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch_geometric.data import InMemoryDataset, Data, Batch\n",
    "from torch.utils.data import DataLoader, Subset\n",
    "from sklearn.calibration import LabelEncoder\n",
    "from generate_dataset import generate_dataset\n",
    "import json "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Constants"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "GENERATED_DATASET_SIZE = 300\n",
    "BATCH_SIZE = 32\n",
    "TRAIN_SAMPLES = 50\n",
    "TRAIN_RATIO = 0.6\n",
    "VAL_RATIO = 0.2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def dict_to_geometric_representation(in_graph_dict: dict, encoder) -> Data:\n",
    "    node_list = []\n",
    "    edge_mappings = []\n",
    "    def traverse_graph(graph = in_graph_dict):\n",
    "        nonlocal node_list\n",
    "        nonlocal edge_mappings\n",
    "        curr_node_index = len(node_list)\n",
    "        encoded_data = encoder(graph[\"val\"])\n",
    "        node_list.append(encoded_data)\n",
    "        if \"children\" in graph.keys():\n",
    "            for child in graph[\"children\"]:\n",
    "                edge_mappings.append((curr_node_index, traverse_graph(child)) ) #I'm retarded.\n",
    "        return curr_node_index\n",
    "    traverse_graph()\n",
    "    nodes = torch.tensor(node_list,dtype=torch.float32)\n",
    "    edges = torch.tensor([[x[0] for x in edge_mappings], [x[1] for x in edge_mappings]], dtype=torch.long) # Probably slow and mentally degenerated\n",
    "    geom_data = Data(x=nodes, edge_index=edges)\n",
    "    return geom_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "OPERATIONS = [\"ADD\", \"MUL\", \"FUNC\", \"POW\"]\n",
    "FUNCTIONS = [\"SIN\", \"COS\", \"TAN\", \"EXP\", \"LOG\"]\n",
    "VARIABLE_ALPHABET = [chr(x) for x in range(ord('a'), ord('z')+1) if chr(x) not in [\"e\", \"i\"]]\n",
    "CLASSIC_CONSTANTS = [\"pi\", \"I\", \"g\",\"e\", \"zoo\"]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_node_attribute_encoder(label_encoder:LabelEncoder, rep = 3):\n",
    "    def node_attr_encoder(attr):\n",
    "        if isinstance(attr, str) and attr in OPERATIONS+FUNCTIONS+CLASSIC_CONSTANTS+VARIABLE_ALPHABET:\n",
    "            res = label_encoder.transform([attr])\n",
    "            return [res[0]]*(rep + 1)\n",
    "        else:\n",
    "            return [0] + [float(attr)]*rep\n",
    "            \n",
    "    return node_attr_encoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_dataset_class(expression):\n",
    "    # Will it be the same for both datasets ? \n",
    "    le = LabelEncoder()\n",
    "    le.fit(OPERATIONS+FUNCTIONS+ATOMICS+VARIABLE_ALPHABET)\n",
    "    class MathExpressionDataset(InMemoryDataset):\n",
    "        def __init__(self, root, transform=None, pre_transform=None, pre_filter=None):\n",
    "            super().__init__(root, transform, pre_transform, pre_filter, force_reload=True)\n",
    "            self.load(self.processed_paths[0])\n",
    "            \n",
    "        @property\n",
    "        def raw_file_names(self):\n",
    "            return ['math_datagen.json']\n",
    "\n",
    "        @property\n",
    "        def processed_file_names(self):\n",
    "            return ['data.pt']\n",
    "        \n",
    "\n",
    "        def process(self):\n",
    "            # Read data into huge `Data` list.\n",
    "            data_list = []\n",
    "            for file in self.raw_file_names:\n",
    "                with open(file) as file_handle:\n",
    "                    object_data = json.load(file_handle)\n",
    "                    for comparison in object_data:\n",
    "                        expr = comparison[expression]\n",
    "                        score = comparison[\"score\"]\n",
    "                        geometric_expr = dict_to_geometric_representation(expr, make_node_attribute_encoder(le))\n",
    "                        geometric_expr.y = score #torch.tensor([score],dtype=torch.float32)\n",
    "                        data_list.append(geometric_expr)\n",
    "                        \n",
    "            if self.pre_filter is not None:\n",
    "                data_list = [data for data in data_list if self.pre_filter(data)]\n",
    "\n",
    "            if self.pre_transform is not None:\n",
    "                data_list = [self.pre_transform(data) for data in data_list]\n",
    "            self.save(data_list, self.processed_paths[0])\n",
    "    return MathExpressionDataset\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ExpressionPairDataset(torch.utils.data.Dataset):\n",
    "    def __init__(self, root, transform=None, pre_transform=None, pre_filter=None):\n",
    "        super().__init__()\n",
    "        self.dataset_l = create_dataset_class(\"expr_l\")(root+\"_l\",transform=None, pre_transform=None, pre_filter=None)\n",
    "        self.dataset_r = create_dataset_class(\"expr_r\")(root+\"_r\",transform=None, pre_transform=None, pre_filter=None)\n",
    "        \n",
    "    @property \n",
    "    def num_features(self):\n",
    "        return self.dataset_l.num_features\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.dataset_l)\n",
    "        \n",
    "    \n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        return self.dataset_l[idx], self.dataset_r[idx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing...\n",
      "Done!\n",
      "Processing...\n",
      "Done!\n"
     ]
    }
   ],
   "source": [
    "generate_dataset(GENERATED_DATASET_SIZE,\"math_datagen.json\") #TODO: Switch to orjson, loading this file will take ages as I generate more data\n",
    "dataset = ExpressionPairDataset(root=\"/dataset\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch import nn\n",
    "from torch.nn import Linear, ReLU\n",
    "import torch.nn.functional as F\n",
    "from torch_geometric.nn import GCNConv, global_mean_pool"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "class FormulaNet(nn.Module):\n",
    "    def __init__(self, hidden_channels: int, embedding_space: int):\n",
    "        super(FormulaNet, self).__init__()\n",
    "        self.dense_1 = Linear(dataset.num_features, dataset.num_features) \n",
    "        self.dense_2 = Linear(dataset.num_features, dataset.num_features) \n",
    "        self.relu_1 = ReLU()\n",
    "        self.gconv_1 = GCNConv(dataset.num_features, hidden_channels)\n",
    "        self.gconv_2 = GCNConv(hidden_channels, hidden_channels)\n",
    "        self.gconv_3 = GCNConv(hidden_channels, hidden_channels)\n",
    "        self.gconv_4 = GCNConv(hidden_channels, hidden_channels)\n",
    "        self.dense_3 = Linear(hidden_channels, embedding_space)\n",
    "        self.dense_4 = Linear(embedding_space, embedding_space)\n",
    "    \n",
    "    def forward(self, x, edge_index, batch):\n",
    "        x = self.dense_1(x)\n",
    "        x = self.relu_1(x)\n",
    "        # x = self.dense_2(x)\n",
    "        # x = self.relu_1(x)\n",
    "        x = self.gconv_1(x, edge_index)\n",
    "        x = self.relu_1(x)\n",
    "        x = self.gconv_2(x, edge_index)\n",
    "        x = self.relu_1(x)\n",
    "        x = self.gconv_3(x, edge_index)\n",
    "        x = self.relu_1(x)\n",
    "        # x = self.gconv_4(x, edge_index)\n",
    "        # x = self.relu_1(x)\n",
    "        x = global_mean_pool(x, batch)\n",
    "        x = F.dropout(x, p=0.3,training=self.training)\n",
    "        x = self.dense_3(x)\n",
    "        x = self.relu_1(x)\n",
    "        # x = self.dense_4(x)\n",
    "        return x\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SiameseFormulaNet(nn.Module):\n",
    "    def __init__(self, hidden_channels, embedding_space):\n",
    "        super(SiameseFormulaNet, self).__init__()\n",
    "        self.formulanet = FormulaNet(hidden_channels, embedding_space)\n",
    "        # self.fc = nn.Sequential(\n",
    "        #     Linear(embedding_space*2, embedding_space),\n",
    "        #     ReLU(inplace=True),\n",
    "        #     Linear(embedding_space, 1)\n",
    "        # )\n",
    "        # self.sigmoid = nn.Sigmoid() # TODO: Only used it for testing purposes, everything is subject to change Okay\n",
    "    \n",
    "\n",
    "    def forward(self, expr_l, expr_r):\n",
    "        # print(expr_l)\n",
    "        # print(\"X = \", expr_l.x)\n",
    "        # print(\"X shape = \", expr_l.x.shape)\n",
    "        # print(\"Batch = \",expr_l.batch)\n",
    "        # print(\"Batch shape = \",expr_l.batch.shape)\n",
    "        # print(\"Y =\", expr_l.y)\n",
    "        # print(\"Edge index = \",expr_l.edge_index)\n",
    "        # print(\"Edge index shape = \",expr_l.edge_index.shape)\n",
    "        \n",
    "        embed_l = self.formulanet(expr_l.x,expr_l.edge_index, expr_l.batch)\n",
    "        embed_l = embed_l.view(embed_l.size()[0], -1)\n",
    "        embed_r = self.formulanet(expr_r.x,expr_r.edge_index, expr_r.batch)\n",
    "        embed_r = embed_r.view(embed_r.size()[0], -1)\n",
    "        \n",
    "        # output = torch.cat((embed_l, embed_r), 1)\n",
    "        \n",
    "        # output = self.fc(output)\n",
    "        # output = self.sigmoid(output)\n",
    "        # return output\n",
    "        return embed_l, embed_r\n",
    "        \n",
    "        \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train_dataset = Subset(dataset, list(range(TRAIN_SAMPLES)))\n",
    "# validation_dataset = Subset(dataset, list(range()))\n",
    "# test_dataset = Subset(dataset, list(range(TRAIN_SAMPLES, -1)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import random_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "total_len = len(dataset.dataset_l)\n",
    "train_len = int(TRAIN_RATIO * total_len)\n",
    "val_len = int(VAL_RATIO * total_len)\n",
    "test_len = total_len - train_len - val_len\n",
    "train_dataset, val_dataset, test_dataset = random_split(dataset, [train_len, val_len, test_len])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def collate(data_list):\n",
    "    batchA = Batch.from_data_list([data[0] for data in data_list])\n",
    "    batchB = Batch.from_data_list([data[1] for data in data_list])\n",
    "    return batchA, batchB\n",
    "# NOTE: Type ignore only for collate_fn_t ... make sure it doesn't get in the way of correct typing for the dataset\n",
    "train_loader = DataLoader(train_dataset, batch_size=BATCH_SIZE, shuffle=True, collate_fn=collate) # type: ignore\n",
    "validation_laoder = DataLoader(val_dataset, batch_size=BATCH_SIZE, shuffle= False, collate_fn = collate)\n",
    "test_loader = DataLoader(test_dataset, batch_size=BATCH_SIZE, shuffle=False, collate_fn=collate) # type: ignore\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cpu\") #torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = SiameseFormulaNet(32,64).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.01)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "def contrastive_loss(embed_l, embed_r, labels, margin=1.0, threshold=0.5):\n",
    "    euclidean_distance = F.pairwise_distance(embed_l, embed_r)\n",
    "    labels = (labels > threshold).float()  # Convert labels to 0 or 1\n",
    "    loss_contrastive = torch.mean((1 - labels) * torch.pow(euclidean_distance, 2) +\n",
    "                                  labels * torch.pow(torch.clamp(margin - euclidean_distance, min=0.0), 2))\n",
    "    return loss_contrastive"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(epoch):\n",
    "    model.train()\n",
    "    epoch_loss = 0\n",
    "    for batch_l, batch_r in tqdm(train_loader, desc=f'Epoch {epoch}'):\n",
    "        batch_l, batch_r = batch_l.to(device), batch_r.to(device)\n",
    "        optimizer.zero_grad()\n",
    "        embed_l, embed_r = model(batch_l, batch_r)\n",
    "        loss = contrastive_loss(embed_l, embed_r, batch_l.y)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        epoch_loss += loss.item()\n",
    "    print(f'Epoch {epoch}, Loss: {epoch_loss / len(train_loader)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "def validate():\n",
    "    model.eval()\n",
    "    test_loss = 0\n",
    "    correct = 0\n",
    "    with torch.no_grad():\n",
    "        for batch_l, batch_r in validation_laoder:\n",
    "            batch_l, batch_r = batch_l.to(device), batch_r.to(device)\n",
    "            embed_l, embed_r = model(batch_l, batch_r)\n",
    "            euclidean_distance = F.pairwise_distance(embed_l, embed_r)\n",
    "            pred = (euclidean_distance < 0.5).float()  # Adjust the threshold as needed\n",
    "            correct += (pred == batch_l.y).sum().item()\n",
    "            test_loss += contrastive_loss(embed_l, embed_r, batch_l.y).item()\n",
    "    test_loss /= len(test_loader)\n",
    "    acc = correct / len(test_dataset)\n",
    "    print(f'Test Loss: {test_loss}, Accuracy: {acc}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ['CUDA_LAUNCH_BLOCKING'] = \"1\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 0: 100%|██████████| 17/17 [00:00<00:00, 19.10it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0, Loss: 0.3230178776909323\n",
      "Test Loss: 0.6289592881997427, Accuracy: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1: 100%|██████████| 17/17 [00:00<00:00, 41.68it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1, Loss: 0.24412733491729288\n",
      "Test Loss: 0.556511844197909, Accuracy: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 2: 100%|██████████| 17/17 [00:00<00:00, 35.03it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2, Loss: 0.22112010331714854\n",
      "Test Loss: 0.4283849000930786, Accuracy: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 3: 100%|██████████| 17/17 [00:00<00:00, 36.23it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3, Loss: 0.23312884218552532\n",
      "Test Loss: 0.3785059303045273, Accuracy: 0.011111111111111112\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 4: 100%|██████████| 17/17 [00:00<00:00, 30.91it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4, Loss: 0.2383178156964919\n",
      "Test Loss: 0.40338556965192157, Accuracy: 0.005555555555555556\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 5: 100%|██████████| 17/17 [00:00<00:00, 29.13it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 5, Loss: 0.21599314843907075\n",
      "Test Loss: 0.3881627966960271, Accuracy: 0.005555555555555556\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 6: 100%|██████████| 17/17 [00:00<00:00, 26.52it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 6, Loss: 0.21737287149709814\n",
      "Test Loss: 0.3631848096847534, Accuracy: 0.005555555555555556\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 7: 100%|██████████| 17/17 [00:00<00:00, 38.75it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 7, Loss: 0.21332467040594885\n",
      "Test Loss: 0.32840150594711304, Accuracy: 0.016666666666666666\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 8: 100%|██████████| 17/17 [00:00<00:00, 28.41it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 8, Loss: 0.21566614245667176\n",
      "Test Loss: 0.3609855870405833, Accuracy: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 9: 100%|██████████| 17/17 [00:00<00:00, 23.88it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 9, Loss: 0.20852970025118658\n",
      "Test Loss: 0.3489117845892906, Accuracy: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "num_epochs = 10\n",
    "for epoch in range(num_epochs):\n",
    "    train(epoch)\n",
    "    validate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "le = LabelEncoder()\n",
    "le.fit(OPERATIONS+FUNCTIONS+ATOMICS+VARIABLE_ALPHABET)\n",
    "eval_node_attr_encoder = make_node_attribute_encoder(le)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "expr_left = {\n",
    "            \"val\": \"COS\",\n",
    "            \"id\": 1,\n",
    "            \"children\": [\n",
    "                {\n",
    "                    \"val\": \"ADD\",\n",
    "                    \"id\": 3,\n",
    "                    \"children\": [\n",
    "                        {\n",
    "                            \"val\": \"j\",\n",
    "                            \"id\": 7\n",
    "                        },\n",
    "                        {\n",
    "                            \"val\": \"POW\",\n",
    "                            \"id\": 8,\n",
    "                            \"children\": [\n",
    "                                {\n",
    "                                    \"val\": \"-9.5\",\n",
    "                                    \"id\": 17\n",
    "                                },\n",
    "                                {\n",
    "                                    \"val\": \"q\",\n",
    "                                    \"id\": 18\n",
    "                                }\n",
    "                            ]\n",
    "                        }\n",
    "                    ]\n",
    "                }\n",
    "            ]\n",
    "        }\n",
    "expr_right = {\n",
    "            \"val\": \"COS\",\n",
    "            \"id\": 1,\n",
    "            \"children\": [\n",
    "                {\n",
    "                    \"val\": \"ADD\",\n",
    "                    \"id\": 3,\n",
    "                    \"children\": [\n",
    "                        {\n",
    "                            \"val\": \"MUL\",\n",
    "                            \"id\": 7,\n",
    "                            \"children\": [\n",
    "                                {\n",
    "                                    \"val\": \"j\",\n",
    "                                    \"id\": 15\n",
    "                                },\n",
    "                                {\n",
    "                                    \"val\": \"-1\",\n",
    "                                    \"id\": 16\n",
    "                                }\n",
    "                            ]\n",
    "                        },\n",
    "                        {\n",
    "                            \"val\": \"POW\",\n",
    "                            \"id\": 8,\n",
    "                            \"children\": [\n",
    "                                {\n",
    "                                    \"val\": \"9.5\",\n",
    "                                    \"id\": 17\n",
    "                                },\n",
    "                                {\n",
    "                                    \"val\": \"MUL\",\n",
    "                                    \"id\": 18,\n",
    "                                    \"children\": [\n",
    "                                        {\n",
    "                                            \"val\": \"q\",\n",
    "                                            \"id\": 37\n",
    "                                        },\n",
    "                                        {\n",
    "                                            \"val\": \"-1\",\n",
    "                                            \"id\": 38\n",
    "                                        }\n",
    "                                    ]\n",
    "                                }\n",
    "                            ]\n",
    "                        }\n",
    "                    ]\n",
    "                }\n",
    "            ]\n",
    "        } \n",
    "\n",
    "expr_right_constant_error = {\n",
    "            \"val\": \"COS\",\n",
    "            \"id\": 1,\n",
    "            \"children\": [\n",
    "                {\n",
    "                    \"val\": \"ADD\",\n",
    "                    \"id\": 3,\n",
    "                    \"children\": [\n",
    "                        {\n",
    "                            \"val\": \"MUL\",\n",
    "                            \"id\": 7,\n",
    "                            \"children\": [\n",
    "                                {\n",
    "                                    \"val\": \"j\",\n",
    "                                    \"id\": 15\n",
    "                                },\n",
    "                                {\n",
    "                                    \"val\": \"-1\",\n",
    "                                    \"id\": 16\n",
    "                                }\n",
    "                            ]\n",
    "                        },\n",
    "                        {\n",
    "                            \"val\": \"POW\",\n",
    "                            \"id\": 8,\n",
    "                            \"children\": [\n",
    "                                {\n",
    "                                    \"val\": \"10.5\",\n",
    "                                    \"id\": 17\n",
    "                                },\n",
    "                                {\n",
    "                                    \"val\": \"MUL\",\n",
    "                                    \"id\": 18,\n",
    "                                    \"children\": [\n",
    "                                        {\n",
    "                                            \"val\": \"q\",\n",
    "                                            \"id\": 37\n",
    "                                        },\n",
    "                                        {\n",
    "                                            \"val\": \"-1\",\n",
    "                                            \"id\": 38\n",
    "                                        }\n",
    "                                    ]\n",
    "                                }\n",
    "                            ]\n",
    "                        }\n",
    "                    ]\n",
    "                }\n",
    "            ]\n",
    "        }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "expr_l_obj = dict_to_geometric_representation(expr_left, eval_node_attr_encoder)\n",
    "expr_r_obj = dict_to_geometric_representation(expr_right, eval_node_attr_encoder)\n",
    "expr_r_c_obj = dict_to_geometric_representation(expr_right_constant_error, eval_node_attr_encoder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_1 = model(expr_l_obj, expr_r_obj)\n",
    "y_2 = model(expr_l_obj, expr_l_obj)\n",
    "y_3 = model(expr_r_obj, expr_r_obj)\n",
    "y_4 = model(expr_r_obj, expr_r_c_obj)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([0.4399], grad_fn=<SumBackward1>)\n",
      "tensor([1.], grad_fn=<SumBackward1>)\n",
      "tensor([1.0000], grad_fn=<SumBackward1>)\n",
      "tensor([1.0000], grad_fn=<SumBackward1>)\n"
     ]
    }
   ],
   "source": [
    "print(F.cosine_similarity(y_1[0], y_1[1]))\n",
    "print(F.cosine_similarity(y_2[0], y_2[1]))\n",
    "print(F.cosine_similarity(y_3[0], y_3[1]))\n",
    "print(F.cosine_similarity(y_4[0], y_4[1]))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from torchviz import make_dot"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Misc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 224,
   "metadata": {},
   "outputs": [],
   "source": [
    "# make_dot(y_f.mean(), params=dict(formulanet.named_parameters()))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
